---
title: "Practical Machine Learning Course Project"
author: "Sooihk Ro"
date: '2022-07-10'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Objective
In this report, data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict which exercise they performed. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The outcome is the "classe" variable. 3 classification models were trained on this dataset using k-fold cross validation: Decision Tree, Gradient Boosted Trees, and Random Forest. The model with the best accuracy and out of sample error rate will be used to predict the test exercise dataset. 

The training dataset is found here: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv.
The test dataset is found: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv. 
All of the data is this document comes from this source:

http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har. 

# Data Preprocessing

# Load libraries and datasets

```{r libraries, warning=FALSE}
library(caret)
library(dplyr)
library(rattle)
set.seed(123)

pml_training <- read.csv("./data/pml-training.csv")
pml_testing <- read.csv("./data/pml-testing.csv") 
dim(pml_training)
dim(pml_testing)
```
There are 19,622 observations and 160 variables for the training dataset. There are 20 observations and 160 variables for the testing dataset. 

## Clean dataset
The dataset needs to be cleaned by removing variables with more than 90% of its data missing, variables irrelevant for the prediction, and variables with near zero variance. The training dataset reduces down to 53 variables. 
``` {r clean}
#remove variables with more than 90% NA
pml_training <- pml_training[, which(colMeans(!is.na(pml_training)) > 0.9)]
#remove irrelavant variables to the outcome
pml_training <- pml_training[,-c(1:7)]
#remove near zero variance predictors 
near_ZeroPredictors <- nearZeroVar(pml_training)
pml_training <- pml_training[,-near_ZeroPredictors]
dim(pml_training)
```

## Data partition 
The training dataset is then splitted into a sub training set and a validation set. 
``` {r partition}
inTrain <- createDataPartition(y=pml_training$classe, p=0.7, list=FALSE)
training <- pml_training[inTrain,]
validation <- pml_training[-inTrain,]
```


# Model Building
The following classification models were used: Decision Tree, Gradient Boosted Trees, and Random Forest. 5-fold cross validation is applied to all models in order to select optimal tuning parameters. 
```{r cross_validation}
#Set trControl parameter to do 5 fold cross valdiation
control <- trainControl(method="cv", number=5, verboseIter=FALSE)
```

## Decision Tree
### Model
```{r tree}
#Set trControl parameter to do 5 fold cross valdiation
tree_fit <- train(classe~., method="rpart", data=training, trControl=control)
tree_fit$finalModel
fancyRpartPlot(tree_fit$finalModel)
```
### Prediction
```{r treePred}
#Set trControl parameter to do 5 fold cross valdiation
#Prediction, estimate performance of model on validation data set
predict_tree <- predict(tree_fit, newdata=validation)
confusion_tree <- confusionMatrix(predict_tree, factor(validation$classe))
confusion_tree
```
## Gradient Boosted Trees
### Model
```{r gbm}
gbm_fit <- train(classe~., method="gbm", data=training, trControl=control, verbose=FALSE)
```
### Prediction 
```{r gbmPred}
#Prediction, estimate performance of model on validation data set
predict_gbm <- predict(gbm_fit, newdata=validation)
confusion_gbm <- confusionMatrix(predict_gbm, factor(validation$classe))
confusion_gbm
```

## Random Forest
### Model
```{r rf}
random_fit <- train(classe~., method="rf", data=training, trControl=control)
```
### Prediction
```{r rfPred}
#Prediction, estimate performance of model on validation data set
predict_rf <- predict(random_fit, newdata=validation)
confusion_rf <- confusionMatrix(predict_rf, factor(validation$classe))
confusion_rf
```

## Results, Model Assessment
``` {r results}
model_names <- c("Decision Tree", "Gradient Boost Trees", "Random Forest")
model_accuracy <- round(c(confusion_tree$overall[1],confusion_gbm$overall[1],confusion_rf$overall[1]),3)
model_oos_error <- 1 - model_accuracy
model_info <- data.frame(Models = model_names, Accuracy = model_accuracy, oos_error = model_oos_error)
model_info
```

Based on the table above, the Random Forest model provides the best accuracy (99.3%) and a small out of sample error rate (0.7%). The Random Forest model will be used for our test dataset to predict the type of exercise. 

## Predictions on test dataset
``` {r prediction}
#Predictions on Test dataset
test_results <- predict(random_fit, pml_testing)
test_results
```
